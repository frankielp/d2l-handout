{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "605affcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52fdc026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4.0,requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c22fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also create x = torch.arange(4.0, requires_grad=True)\n",
    "\n",
    "x.grad  # The gradient is None by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1451214e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(28.)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MXNet sẽ chỉ dựng đồ thị khi được ra lệnh rõ ràng\n",
    "with autograd.record():\n",
    "    y = 2 * np.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5a118e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7c7eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7d8bca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad94a46",
   "metadata": {},
   "source": [
    "# Truyền ngược cho các biến không phải Số vô hướng\n",
    "Về mặt kỹ thuật, khi y không phải một số vô hướng, cách diễn giải tự nhiên nhất cho vi phân của một vector y theo vector x đó là một ma trận. Với các bậc và chiều cao hơn của y và x, kết quả của phép vi phân có thể là một tensor bậc cao.\n",
    "\n",
    "Tuy nhiên, trong khi những đối tượng như trên xuất hiện trong học máy nâng cao (bao gồm học sâu), thường thì khi ta gọi lan truyền ngược trên một vector, ta đang cố tính toán đạo hàm của hàm mất mát theo mỗi batch bao gồm một vài mẫu huấn luyện. Ở đây, ý định của ta không phải là tính toán ma trận vi phân mà là tổng của các đạo hàm riêng được tính toán một cách độc lập cho mỗi mẫu trong batch.\n",
    "\n",
    "Vậy nên khi ta gọi backward lên một biến vector y – là một hàm của x, MXNet sẽ cho rằng ta muốn tính tổng của các gradient. Nói ngắn gọn, MXNet sẽ tạo một biến mới có giá trị là số vô hướng bằng cách cộng lại các phần tử trong y và tính gradient theo x của biến mới này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa1dc8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True]),\n",
       " array([0., 2., 4., 6.]),\n",
       " array([0., 1., 4., 9.]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = x * x  # y is a vector\n",
    "y.backward()\n",
    "\n",
    "u = x.copy()\n",
    "u.attach_grad()\n",
    "with autograd.record():\n",
    "    v = (u * u).sum()  # v is a scalar\n",
    "v.backward()\n",
    "\n",
    "x.grad == u.grad, x.grad,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6083124e",
   "metadata": {},
   "source": [
    "# Tách rời Tính toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "950f21c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True]), array([0., 1., 4., 9.]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with autograd.record():\n",
    "    y = x * x\n",
    "    u = y.detach()\n",
    "    z = u * x\n",
    "z.backward()\n",
    "x.grad == u,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de932879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb00e583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1., -1., -1.]), array([5., 5., 5., 5.]), array([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.ones(4) * 2\n",
    "y.attach_grad()\n",
    "with autograd.record():\n",
    "    u = x * y\n",
    "    u.attach_grad()  # Implicitly run u = u.detach()\n",
    "    z = 5 * u - x\n",
    "z.backward()\n",
    "x.grad, u.grad, y.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3431340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3.]), array([2., 2., 2., 2.]), array([0., 2., 4., 6.]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y,u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0670f8",
   "metadata": {},
   "source": [
    "#  Tính gradient của Luồng điều khiển Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea6373d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while np.linalg.norm(b) < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2dce6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.normal()\n",
    "a.attach_grad()\n",
    "with autograd.record():\n",
    "    d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be1835c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408f5af",
   "metadata": {},
   "source": [
    "#  Chế độ huấn luyện và Chế độ dự đoán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d286622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(autograd.is_training())\n",
    "with autograd.record():\n",
    "    print(autograd.is_training())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc89db",
   "metadata": {},
   "source": [
    "# Tóm tắt\n",
    "\n",
    "MXNet cung cấp gói autograd để tự động hóa việc tính toán đạo hàm. Để sử dụng nó, đầu tiên ta gắn gradient cho các biến mà ta muốn lấy đạo hàm riêng theo nó. Sau đó ta ghi lại tính toán của giá trị mục tiêu, thực thi hàm backward của nó và truy cập kết quả gradient thông qua thuộc tính grad của các biến.\n",
    "\n",
    "Ta có thể tách rời gradient để kiểm soát những phần tính toán được sử dụng trong hàm backward.\n",
    "\n",
    "Các chế độ chạy của MXNet bao gồm chế độ huấn luyện và chế độ dự đoán. Ta có thể kiểm tra chế độ đang chạy bằng cách gọi hàm is_training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
